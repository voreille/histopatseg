{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75bce56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "import umap\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from histopatseg.visualization.visualization import plot_embeddings\n",
    "from histopatseg.evaluation.utils import aggregate_tile_embeddings, custom_balanced_group_kfold\n",
    "from histopatseg.evaluation.prototype_classifier import PrototypeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c3d60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = Path(\".\").resolve().parent\n",
    "print(f\"Project Directory: {project_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d907263a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_file = project_dir / \"data/processed/embeddings/lunghist700_20x_UNI2_embeddings.npz\"\n",
    "metadata  = pd.read_csv(project_dir / \"/home/valentin/workspaces/histopatseg/data/processed/LungHist700_tiled/LungHist700_20x/metadata.csv\").set_index(\"tile_id\")\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04591c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the embeddings\n",
    "data = np.load(embedding_file)\n",
    "embeddings = data[\"embeddings\"]\n",
    "tile_ids = data[\"tile_ids\"]\n",
    "embedding_dim = data[\"embedding_dim\"]\n",
    "\n",
    "# Check if all embedding tile_ids are in the metadata index\n",
    "missing_ids = [id for id in tile_ids if id not in metadata.index]\n",
    "if missing_ids:\n",
    "    print(f\"Warning: {len(missing_ids)} tile_ids from embeddings are not in metadata\")\n",
    "    print(f\"First few missing IDs: {missing_ids[:5]}\")\n",
    "\n",
    "metadata = metadata.reindex(tile_ids)\n",
    "metadata[\"subclass\"] = metadata.apply(\n",
    "    lambda row: row[\"superclass\"]\n",
    "    if pd.isna(row[\"subclass\"]) and row[\"superclass\"] == \"nor\"\n",
    "    else row[\"subclass\"],\n",
    "    axis=1,\n",
    ")\n",
    " \n",
    "\n",
    "# Print basic information\n",
    "print(f\"Loaded {len(embeddings)} embeddings with dimensionality {embeddings.shape[1]}\")\n",
    "print(f\"Embedding dimension from model: {embedding_dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ca3b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_aca = metadata[\"superclass\"] == \"aca\"\n",
    "metadata = metadata[mask_aca]\n",
    "embeddings = embeddings[mask_aca]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ff8696",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = metadata[\"class_name\"].values\n",
    "groups = metadata[\"patient_id\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740f1095",
   "metadata": {},
   "outputs": [],
   "source": [
    "norms = np.linalg.norm(embeddings, axis=1)\n",
    "print(\"Mean norm:\", norms.mean())\n",
    "print(\"Min norm:\", norms.min(), \"Max norm:\", norms.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7f0001",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = list(custom_balanced_group_kfold(\n",
    "    embeddings,\n",
    "    y,\n",
    "    groups,\n",
    "    n_splits=4,\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74cc419",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a15e38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx, test_idx = cv[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4ae7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = normalize(embeddings, norm=\"l2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525403d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_image_pcs_for_normalized(embeddings, image_ids, n_components=2):\n",
    "    \"\"\"\n",
    "    Remove principal components that capture image-level variation,\n",
    "    specially adapted for L2-normalized embeddings.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    embeddings : numpy array of shape (n_samples, n_features)\n",
    "        L2-normalized embedding vectors\n",
    "    image_ids : numpy array of shape (n_samples,)\n",
    "        Image ID for each tile\n",
    "    n_components : int\n",
    "        Number of principal components to remove\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    corrected_embeddings : numpy array of shape (n_samples, n_features)\n",
    "        Embeddings with image-level PCs removed\n",
    "    \"\"\"\n",
    "    unique_image_ids = np.unique(image_ids)\n",
    "    \n",
    "    # Compute image means\n",
    "    image_means = np.zeros((len(unique_image_ids), embeddings.shape[1]))\n",
    "    for i, img_id in enumerate(unique_image_ids):\n",
    "        mask = image_ids == img_id\n",
    "        # For L2-normalized vectors, take the mean and re-normalize\n",
    "        mean_vector = embeddings[mask].mean(axis=0)\n",
    "        image_means[i] = mean_vector / np.linalg.norm(mean_vector)\n",
    "    \n",
    "    # Compute PCA on image means to identify image-specific directions\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca.fit(image_means)\n",
    "    image_pcs = pca.components_\n",
    "    \n",
    "    # For each embedding, remove projection onto image PCs\n",
    "    corrected_embeddings = embeddings.copy()\n",
    "    for i in range(len(embeddings)):\n",
    "        embedding = embeddings[i]\n",
    "        \n",
    "        # Remove projections onto image PCs\n",
    "        for pc in image_pcs:\n",
    "            # Calculate projection\n",
    "            proj = np.dot(embedding, pc) * pc\n",
    "            # Subtract projection\n",
    "            embedding = embedding - proj\n",
    "            \n",
    "        # Renormalize to unit length\n",
    "        corrected_embeddings[i] = embedding / np.linalg.norm(embedding)\n",
    "    \n",
    "    return corrected_embeddings\n",
    "\n",
    "# Apply to your normalized embeddings\n",
    "image_ids = metadata[\"image_id\"].values\n",
    "embeddings = remove_image_pcs_for_normalized(embeddings, image_ids, n_components=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23065c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_elbow_method(embeddings, max_clusters=20):\n",
    "    \"\"\"Plot the elbow method to find optimal number of clusters.\"\"\"\n",
    "    inertia = []\n",
    "    k_range = range(1, max_clusters + 1)\n",
    "    \n",
    "    for k in k_range:\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42, n_init=\"auto\")\n",
    "        kmeans.fit(embeddings)\n",
    "        inertia.append(kmeans.inertia_)\n",
    "    \n",
    "    # Plot the elbow\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(k_range, inertia, 'o-', markersize=8)\n",
    "    plt.xlabel('Number of Clusters (k)')\n",
    "    plt.ylabel('Inertia (Within-Cluster Sum of Squares)')\n",
    "    plt.title('Elbow Method for Optimal k')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Calculate the angle/second derivative to find the elbow point\n",
    "    angles = []\n",
    "    for i in range(1, len(inertia)-1):\n",
    "        x1, y1 = k_range[i-1], inertia[i-1]\n",
    "        x2, y2 = k_range[i], inertia[i]\n",
    "        x3, y3 = k_range[i+1], inertia[i+1]\n",
    "        \n",
    "        # Calculate the angle between the two line segments\n",
    "        angle = np.abs(np.arctan2(y3-y2, x3-x2) - np.arctan2(y2-y1, x2-x1))\n",
    "        angles.append((k_range[i], angle))\n",
    "    \n",
    "    # Find the point with maximum angle\n",
    "    elbow_point = max(angles, key=lambda x: x[1])[0]\n",
    "    plt.axvline(x=elbow_point, color='r', linestyle='--', label=f'Elbow point: k={elbow_point}')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    return elbow_point\n",
    "\n",
    "# Normalize embeddings before clustering\n",
    "embeddings_norm = normalize(embeddings, norm=\"l2\")\n",
    "elbow_k = plot_elbow_method(embeddings_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10e6151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit k-means\n",
    "n_clusters = 8  # you can tune this (e.g., 5-8 for LUAD patterns)\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=\"auto\")\n",
    "cluster_labels = kmeans.fit_predict(embeddings)\n",
    "\n",
    "# Store cluster assignments in metadata\n",
    "metadata[\"cluster\"] = cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e766f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d699594a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Get LUAD metadata for training and test\n",
    "metadata_train = metadata.iloc[train_idx]\n",
    "metadata_test = metadata.iloc[test_idx]\n",
    "\n",
    "\n",
    "# Helper function to compute histograms per WSI\n",
    "def compute_wsi_histograms(meta, n_clusters):\n",
    "    wsi_histograms = {}\n",
    "    wsi_labels = {}\n",
    "\n",
    "    for image_id, group in meta.groupby(\"image_id\"):\n",
    "        cluster_counts = np.bincount(group[\"cluster\"], minlength=n_clusters)\n",
    "        histogram = cluster_counts / cluster_counts.sum()  # normalize\n",
    "        wsi_histograms[image_id] = histogram\n",
    "        wsi_labels[image_id] = group[\"class_name\"].iloc[0]  # assuming consistent label\n",
    "\n",
    "    return wsi_histograms, wsi_labels\n",
    "\n",
    "# Compute histograms\n",
    "train_histograms, train_labels = compute_wsi_histograms(metadata_train, n_clusters)\n",
    "test_histograms, test_labels = compute_wsi_histograms(metadata_test, n_clusters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dbfd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Convert dicts to arrays\n",
    "X_train = np.stack(list(train_histograms.values()))\n",
    "y_train = np.array(list(train_labels.values()))\n",
    "\n",
    "X_test = np.stack(list(test_histograms.values()))\n",
    "y_test = np.array(list(test_labels.values()))\n",
    "\n",
    "# Train logistic regression\n",
    "clf = LogisticRegression(multi_class=\"multinomial\", max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcb7ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f8aab4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchpl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
